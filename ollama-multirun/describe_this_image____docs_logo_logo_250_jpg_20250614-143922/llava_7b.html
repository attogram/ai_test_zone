  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: llava:7b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>describe_this_image____docs_logo_logo_250_jpg</a>: <b>llava:7b</b>: 20250614-143922<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./granite3_2_vision_2b.html'>granite3.2-vision:2b</a> 
<a href='./minicpm_v_8b.html'>minicpm-v:8b</a> 
<a href='./qwen2_5vl_3b.html'>qwen2.5vl:3b</a> 
<a href='./qwen2_5vl_7b.html'>qwen2.5vl:7b</a> 
<a href='./gemma3_4b.html'>gemma3:4b</a> 
<b>llava:7b</b> 
<a href='./llava_llama3_8b.html'>llava-llama3:8b</a> 
<a href='./llava_phi3_3_8b.html'>llava-phi3:3.8b</a> 
<a href='./bakllava_7b.html'>bakllava:7b</a> 
<a href='./moondream_1_8b.html'>moondream:1.8b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./describe_this_image____docs_logo_logo_250_jpg.prompt.yaml'>yaml</a>)
  words:4  bytes:46<br />
<textarea readonly rows='1'>Describe this image: ./docs/logo/logo-250.jpg</textarea>
</p>
<div class='box'><a target='image' href='logo-250.jpg'><img src='logo-250.jpg' alt='./docs/logo/logo-250.jpg' width='250' /></a></div><br /><p>Output: llava:7b (<a href='./llava_7b.output.txt'>raw</a>)<br />
<textarea readonly rows='4'> The image is a digital illustration featuring three alpacas, which are large, furry animals with short necks and stout bodies, standing side by side in what appears to be an IT server room. Each alpaca has distinctive facial features, such as large eyes and small mouths, and one of them seems to be looking directly at the viewer. They are all dressed in pink hoodie sweaters, which add a whimsical touch to their otherwise ordinary appearance. Behind the alpacas is a server rack filled with various pieces of hardware, including servers and routers. The room is lit by fluorescent lighting, casting shadows on the walls and floor. The overall atmosphere is playful and fantastical, with an emphasis on the juxtaposition between these adorable creatures and the serious environment they are in. There is no visible text within the image. </textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./llava_7b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>139</td></tr>
<tr><td class='left'>bytes</td><td>843</td></tr>
<tr><td class='left'>total duration</td><td>13.587836083s</td></tr>
<tr><td class='left'>load duration</td><td>15.173708ms</td></tr>
<tr><td class='left'>prompt eval count</td><td>592 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>3.835423s</td></tr>
<tr><td class='left'>prompt eval rate</td><td>154.35 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>185 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>9.735239875s</td></tr>
<tr><td class='left'>eval rate</td><td>19.00 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./llava_7b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/llava:7b'>llava:7b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>llama</td></tr>
<tr><td class='left'>size</td><td class='left'>7.0 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>7.2B</td></tr>
<tr><td class='left'>context length</td><td class='left'>32768</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>4096</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q4_0</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br />vision<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>15G + 866M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>describe_this_image____docs_logo_logo_250_jpg</a>: <b>llava:7b</b>: 20250614-143922</p>
<p>page created:   2025-06-14 14:42:06</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v5.0</p>
</footer></body></html>
