  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: llava-phi3:3.8b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>describe_this_image____docs_logo_logo_250_jpg</a>: <b>llava-phi3:3.8b</b>: 20250614-143922<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./granite3_2_vision_2b.html'>granite3.2-vision:2b</a> 
<a href='./minicpm_v_8b.html'>minicpm-v:8b</a> 
<a href='./qwen2_5vl_3b.html'>qwen2.5vl:3b</a> 
<a href='./qwen2_5vl_7b.html'>qwen2.5vl:7b</a> 
<a href='./gemma3_4b.html'>gemma3:4b</a> 
<a href='./llava_7b.html'>llava:7b</a> 
<a href='./llava_llama3_8b.html'>llava-llama3:8b</a> 
<b>llava-phi3:3.8b</b> 
<a href='./bakllava_7b.html'>bakllava:7b</a> 
<a href='./moondream_1_8b.html'>moondream:1.8b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./describe_this_image____docs_logo_logo_250_jpg.prompt.yaml'>yaml</a>)
  words:4  bytes:46<br />
<textarea readonly rows='1'>Describe this image: ./docs/logo/logo-250.jpg</textarea>
</p>
<div class='box'><a target='image' href='logo-250.jpg'><img src='logo-250.jpg' alt='./docs/logo/logo-250.jpg' width='250' /></a></div><br /><p>Output: llava-phi3:3.8b (<a href='./llava_phi3_3_8b.output.txt'>raw</a>)<br />
<textarea readonly rows='6'>In the center of a dimly lit room, three cartoon llamas stand side by side on a blue floor. The llama on the left is facing towards us, its black eyes and nose standing out against its vibrant pink body. In the middle, another llama is also turned to face us, but it has a unique feature - white spots adorning its head and neck. On the right, the third llama stands with its back to us, creating a sense of depth in the image.

The room around them is filled with rows upon rows of shelves, each one filled with what appears to be blue lights. The walls are painted a dark purple, providing a stark contrast to the brightly colored floor and llamas. Above them, a white ceiling houses a solitary light fixture that casts a soft glow over the scene. The precise arrangement of the objects and their relative positions contribute to the overall composition of the image.</textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./llava_phi3_3_8b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>161</td></tr>
<tr><td class='left'>bytes</td><td>871</td></tr>
<tr><td class='left'>total duration</td><td>10.020088958s</td></tr>
<tr><td class='left'>load duration</td><td>10.895583ms</td></tr>
<tr><td class='left'>prompt eval count</td><td>594 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>2.882995s</td></tr>
<tr><td class='left'>prompt eval rate</td><td>206.04 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>204 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>7.124726833s</td></tr>
<tr><td class='left'>eval rate</td><td>28.63 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./llava_phi3_3_8b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/llava-phi3:3.8b'>llava-phi3:3.8b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>llama</td></tr>
<tr><td class='left'>size</td><td class='left'>7.4 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>3.8B</td></tr>
<tr><td class='left'>context length</td><td class='left'>4096</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>3072</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q4_K_M</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br />vision<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>14G + 1167M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>describe_this_image____docs_logo_logo_250_jpg</a>: <b>llava-phi3:3.8b</b>: 20250614-143922</p>
<p>page created:   2025-06-14 14:42:34</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v5.0</p>
</footer></body></html>
