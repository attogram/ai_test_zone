  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: llava-phi3:3.8b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>describe_this_image____docs_logo_logo_250_jpg</a>: <b>llava-phi3:3.8b</b>: 20250615-224247<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./granite3_2_vision_2b.html'>granite3.2-vision:2b</a> 
<a href='./minicpm_v_8b.html'>minicpm-v:8b</a> 
<a href='./qwen2_5vl_3b.html'>qwen2.5vl:3b</a> 
<a href='./qwen2_5vl_7b.html'>qwen2.5vl:7b</a> 
<a href='./gemma3_4b.html'>gemma3:4b</a> 
<a href='./llava_7b.html'>llava:7b</a> 
<a href='./llava_llama3_8b.html'>llava-llama3:8b</a> 
<b>llava-phi3:3.8b</b> 
<a href='./bakllava_7b.html'>bakllava:7b</a> 
<a href='./moondream_1_8b.html'>moondream:1.8b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./describe_this_image____docs_logo_logo_250_jpg.prompt.yaml'>yaml</a>)
  words:4  bytes:46<br />
<textarea readonly rows='1'>Describe this image: ./docs/logo/logo-250.jpg</textarea>
</p>
<div class='box'><a target='image' href='logo-250.jpg'><img src='logo-250.jpg' alt='./docs/logo/logo-250.jpg' width='250' /></a></div><br /><p>Output: llava-phi3:3.8b (<a href='./llava_phi3_3_8b.output.txt'>raw</a>)<br />
<textarea readonly rows='8'>In the image, there are three alpaca-like creatures standing in a narrow passage. The first one is on the left and has a slight blur to it, giving an impression of motion or depth of field. The other two alpacas stand upright with their legs slightly apart, creating a triangular formation. They are facing towards us, as if they are about to interact with us. 

The background is dark and filled with blue lights that create a futuristic ambiance. On the right side of the image, there are racks of data storage units, suggesting that this place could be some sort of technological or scientific facility. The creatures and the storage units coexist in this space, creating an interesting juxtaposition between nature-like alpacas and advanced technology. 

The text &quot;ALPAKA&quot; is visible on one of the creatures, indicating that these are not ordinary alpacas but possibly some sort of digital or artificial representation of them. The overall image gives a sense of intrigue about what lies in this futuristic setting.</textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./llava_phi3_3_8b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>169</td></tr>
<tr><td class='left'>bytes</td><td>1021</td></tr>
<tr><td class='left'>total duration</td><td>11.586295584s</td></tr>
<tr><td class='left'>load duration</td><td>12.777459ms</td></tr>
<tr><td class='left'>prompt eval count</td><td>594 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>2.895120542s</td></tr>
<tr><td class='left'>prompt eval rate</td><td>205.17 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>232 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>8.676939833s</td></tr>
<tr><td class='left'>eval rate</td><td>26.74 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./llava_phi3_3_8b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/llava-phi3:3.8b'>llava-phi3:3.8b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>llama</td></tr>
<tr><td class='left'>size</td><td class='left'>7.4 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>3.8B</td></tr>
<tr><td class='left'>context length</td><td class='left'>4096</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>3072</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q4_K_M</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br />vision<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>14G + 1322M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>describe_this_image____docs_logo_logo_250_jpg</a>: <b>llava-phi3:3.8b</b>: 20250615-224247</p>
<p>page created:   2025-06-15 22:46:02</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v5.1</p>
</footer></body></html>
