  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: refactor_this_bash_function___currently_it_makes_</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <b>refactor_this_bash_function___currently_it_makes_</b>: 20250614-132534<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./qwen2_5_coder_7b.html'>qwen2.5-coder:7b</a> 
<a href='./codellama_7b.html'>codellama:7b</a> 
<a href='./starcoder_7b.html'>starcoder:7b</a> 
<a href='./stable_code_3b.html'>stable-code:3b</a> 
<a href='./deepcoder_1_5b.html'>deepcoder:1.5b</a> 
<a href='./dolphin3_8b.html'>dolphin3:8b</a> 
<a href='./gemma_2b.html'>gemma:2b</a> 
<a href='./granite3_3_2b.html'>granite3.3:2b</a> 
<a href='./mistral_7b.html'>mistral:7b</a> 
<a href='./qwen3_1_7b.html'>qwen3:1.7b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./refactor_this_bash_function___currently_it_makes_.prompt.yaml'>yaml</a>)
  words:143  bytes:1093<br />
<textarea readonly rows='10'>Refactor this bash function:
- currently it makes $statsInfo array via reading $statsFile, then loops through it to add the values to the index file.
- refactor to not use the $statsInfo array, just read $statsFile directly and output the values directly into the index file.
- The function should still take the same parameters and produce the same output.

Code:

function addModelToIndexFile {
    responseWords=$(wc -w &lt; &quot;$modelFile&quot; | awk &#39;{print $1}&#39;)
    responseBytes=$(wc -c &lt; &quot;$modelFile&quot; | awk &#39;{print $1}&#39;)

    # parse the stats file into an array, splitting on : character, getting the second part of each line
    statsInfo=()
    while read -r line; do
      value=$(echo &quot;$line&quot; | cut -d &#39;:&#39; -f2)
      statsInfo+=(&quot;$value&quot;)
    done &lt; &quot;$statsFile&quot;

    (
        echo &quot;&lt;tr&gt;&lt;td class=&#39;left&#39;&gt;&lt;a href=&#39;./$model.html&#39;&gt;$model&lt;/a&gt;&lt;/td&gt;&lt;td &gt;$responseWords&lt;/td&gt;&lt;td&gt;${responseBytes}&lt;/td&gt;&quot;
        for value in &quot;${statsInfo[@]}&quot;; do
            if [[ -n &quot;$value&quot; ]]; then
              echo &quot;&lt;td&gt;${value}&lt;/td&gt;&quot;;
            fi
        done
        echo &quot;&lt;/tr&gt;&quot;
    ) &gt;&gt; &quot;$indexFile&quot;
}</textarea>
</p>

<table>
  <tr>
    <th class='left'>model</th>
    <th>words</th>
    <th>bytes</th>
    <th>total<br />duration</th>
    <th>load<br />duration</th>
    <th>prompt eval<br />count</th>
    <th>prompt eval<br />duration</th>
    <th>prompt eval<br />rate</th>
    <th>eval<br />count</th>
    <th>eval<br />duration</th>
    <th>eval<br />rate</th>
  </tr>
<tr>
<td class='left'><a href='./qwen2_5_coder_7b.html'>qwen2.5-coder:7b</a></td>
<td>176</td>
<td>1355</td>
<td>21.0618275s</td>
<td>17.523875ms</td>
<td>309 token(s)</td>
<td>2.128589208s</td>
<td>145.17 tokens/s</td>
<td>333 token(s)</td>
<td>18.915040709s</td>
<td>17.61 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./codellama_7b.html'>codellama:7b</a></td>
<td>123</td>
<td>891</td>
<td>16.098172167s</td>
<td>12.354584ms</td>
<td>336 token(s)</td>
<td>2.424721084s</td>
<td>138.57 tokens/s</td>
<td>263 token(s)</td>
<td>13.660186916s</td>
<td>19.25 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./starcoder_7b.html'>starcoder:7b</a></td>
<td>69</td>
<td>647</td>
<td>14.7156465s</td>
<td>13.070709ms</td>
<td>319 token(s)</td>
<td>2.017135666s</td>
<td>158.15 tokens/s</td>
<td>224 token(s)</td>
<td>12.684782125s</td>
<td>17.66 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./stable_code_3b.html'>stable-code:3b</a></td>
<td>133</td>
<td>1012</td>
<td>9.35481075s</td>
<td>10.891875ms</td>
<td>365 token(s)</td>
<td>1.450132083s</td>
<td>251.70 tokens/s</td>
<td>299 token(s)</td>
<td>7.893164584s</td>
<td>37.88 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./deepcoder_1_5b.html'>deepcoder:1.5b</a></td>
<td>4497</td>
<td>28816</td>
<td>2m27.492376667s</td>
<td>19.729333ms</td>
<td>283 token(s)</td>
<td>477.227542ms</td>
<td>593.01 tokens/s</td>
<td>6146 token(s)</td>
<td>2m26.994775583s</td>
<td>41.81 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./dolphin3_8b.html'>dolphin3:8b</a></td>
<td>87</td>
<td>739</td>
<td>14.605707125s</td>
<td>16.04ms</td>
<td>303 token(s)</td>
<td>2.162709084s</td>
<td>140.10 tokens/s</td>
<td>199 token(s)</td>
<td>12.426358583s</td>
<td>16.01 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./gemma_2b.html'>gemma:2b</a></td>
<td>130</td>
<td>966</td>
<td>6.552518792s</td>
<td>20.451917ms</td>
<td>321 token(s)</td>
<td>650.661167ms</td>
<td>493.34 tokens/s</td>
<td>258 token(s)</td>
<td>5.880852083s</td>
<td>43.87 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./granite3_3_2b.html'>granite3.3:2b</a></td>
<td>112</td>
<td>898</td>
<td>7.155068625s</td>
<td>14.689708ms</td>
<td>326 token(s)</td>
<td>976.61575ms</td>
<td>333.81 tokens/s</td>
<td>228 token(s)</td>
<td>6.162484166s</td>
<td>37.00 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./mistral_7b.html'>mistral:7b</a></td>
<td>171</td>
<td>1238</td>
<td>20.808285333s</td>
<td>11.120625ms</td>
<td>321 token(s)</td>
<td>2.146399917s</td>
<td>149.55 tokens/s</td>
<td>347 token(s)</td>
<td>18.650058625s</td>
<td>18.61 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./qwen3_1_7b.html'>qwen3:1.7b</a></td>
<td>2766</td>
<td>17261</td>
<td>1m59.683683833s</td>
<td>19.611833ms</td>
<td>290 token(s)</td>
<td>553.142ms</td>
<td>524.28 tokens/s</td>
<td>4514 token(s)</td>
<td>1m59.110299625s</td>
<td>37.90 tokens/s</td>
</tr>
</table>
<br /><br />
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>12G + 646M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p><a href='../index.html'>ollama-multirun</a>: <b>refactor_this_bash_function___currently_it_makes_</b>: 20250614-132534</p>
<p>page created:   2025-06-14 13:32:24</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v5.0</p>
</footer></body></html>
