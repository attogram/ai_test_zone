  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: help_me_a_write_a_php_function_to_parse_data_from_</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <b>help_me_a_write_a_php_function_to_parse_data_from_</b>: 20250703-133310<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./bakllava_7b.html'>bakllava:7b</a> 
<a href='./codellama_7b.html'>codellama:7b</a> 
<a href='./deepcoder_1_5b.html'>deepcoder:1.5b</a> 
<a href='./deepseek_r1_1_5b.html'>deepseek-r1:1.5b</a> 
<a href='./deepseek_r1_8b.html'>deepseek-r1:8b</a> 
<a href='./dolphin_mistral_7b.html'>dolphin-mistral:7b</a> 
<a href='./dolphin3_8b.html'>dolphin3:8b</a> 
<a href='./gemma3_1b.html'>gemma3:1b</a> 
<a href='./gemma3_4b.html'>gemma3:4b</a> 
<a href='./gemma_2b.html'>gemma:2b</a> 
<a href='./granite3_2_vision_2b.html'>granite3.2-vision:2b</a> 
<a href='./granite3_3_2b.html'>granite3.3:2b</a> 
<a href='./huihui_ai_baronllm_abliterated_8b.html'>huihui_ai/baronllm-abliterated:8b</a> 
<a href='./llama3_groq_tool_use_8b.html'>llama3-groq-tool-use:8b</a> 
<a href='./llama3_2_1b.html'>llama3.2:1b</a> 
<a href='./llava_llama3_8b.html'>llava-llama3:8b</a> 
<a href='./llava_phi3_3_8b.html'>llava-phi3:3.8b</a> 
<a href='./llava_7b.html'>llava:7b</a> 
<a href='./minicpm_v_8b.html'>minicpm-v:8b</a> 
<a href='./mistral_7b.html'>mistral:7b</a> 
<a href='./qwen2_5_coder_7b.html'>qwen2.5-coder:7b</a> 
<a href='./qwen2_5vl_3b.html'>qwen2.5vl:3b</a> 
<a href='./qwen2_5vl_7b.html'>qwen2.5vl:7b</a> 
<a href='./qwen3_1_7b.html'>qwen3:1.7b</a> 
<a href='./qwen3_8b.html'>qwen3:8b</a> 
<a href='./stable_code_3b.html'>stable-code:3b</a> 
<a href='./starcoder_7b.html'>starcoder:7b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./help_me_a_write_a_php_function_to_parse_data_from_.prompt.yaml'>yaml</a>)
  words:177  bytes:1491<br />
<textarea readonly rows='10'>Help me a write a PHP function to parse data from this model.info.txt file:

- in the Model section, each line is in format &quot;name    value&quot;
  - for each line, save as a PHP variable: name=&quot;$value&quot; 
  - example:  line &quot;architecture        granite&quot; parses to: architecture=&quot;granite&quot;
 
- in the Capabilities section, each line is a single keyword
  - save all the keywords into a PHP array

- in the System section, single or multiple lines showing the system prompt
  - save as var $systemPrompt

- In the Parameters section (has same format as Model section)
  - only save the &#39;temperature&#39; value

- Allow that any section or any line may be missing

example model.info.txt contents:

  Model
    architecture        granite    
    parameters          2.5B       
    context length      16384      
    embedding length    2048       
    quantization        Q4_K_M     

  Capabilities
    completion    
    tools         
    vision        

  Projector
    architecture        clip       
    parameters          441.86M    
    embedding length    1152       
    dimensions          0          

  Parameters
    num_ctx        16384    
    temperature    0        

  System
    A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful,    
      detailed, and polite answers to the user&#39;s questions.                                                   

  License
    Apache License               
    Version 2.0, January 2004    
    ...</textarea>
</p>

<table>
  <tr>
    <th class='left'>model</th>
    <th>words</th>
    <th>bytes</th>
    <th>total<br />duration</th>
    <th>load<br />duration</th>
    <th>prompt eval<br />count</th>
    <th>prompt eval<br />duration</th>
    <th>prompt eval<br />rate</th>
    <th>eval<br />count</th>
    <th>eval<br />duration</th>
    <th>eval<br />rate</th>
  </tr>
<tr>
<td class='left'><a href='./bakllava_7b.html'>bakllava:7b</a></td>
<td>18</td>
<td>86</td>
<td>3.873568708s</td>
<td>10.3215ms</td>
<td>395 token(s)</td>
<td>2.792545625s</td>
<td>141.45 tokens/s</td>
<td>22 token(s)</td>
<td>1.070121s</td>
<td>20.56 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./codellama_7b.html'>codellama:7b</a></td>
<td>614</td>
<td>4264</td>
<td>1m17.212036167s</td>
<td>11.016583ms</td>
<td>404 token(s)</td>
<td>3.31376975s</td>
<td>121.92 tokens/s</td>
<td>1194 token(s)</td>
<td>1m13.883377292s</td>
<td>16.16 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./deepcoder_1_5b.html'>deepcoder:1.5b</a></td>
<td>469</td>
<td>3760</td>
<td>3m58.346421209s</td>
<td>32.103959ms</td>
<td>340 token(s)</td>
<td>554.421792ms</td>
<td>613.25 tokens/s</td>
<td>8731 token(s)</td>
<td>3m57.758604208s</td>
<td>36.72 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./deepseek_r1_1_5b.html'>deepseek-r1:1.5b</a></td>
<td>6</td>
<td>43</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td class='left'><a href='./deepseek_r1_8b.html'>deepseek-r1:8b</a></td>
<td>6</td>
<td>43</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td class='left'><a href='./dolphin_mistral_7b.html'>dolphin-mistral:7b</a></td>
<td>196</td>
<td>2023</td>
<td>32.988849417s</td>
<td>11.648042ms</td>
<td>411 token(s)</td>
<td>2.885287875s</td>
<td>142.45 tokens/s</td>
<td>559 token(s)</td>
<td>30.091163s</td>
<td>18.58 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./dolphin3_8b.html'>dolphin3:8b</a></td>
<td>238</td>
<td>2152</td>
<td>34.772672041s</td>
<td>31.468416ms</td>
<td>345 token(s)</td>
<td>4.098815417s</td>
<td>84.17 tokens/s</td>
<td>511 token(s)</td>
<td>30.641599875s</td>
<td>16.68 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./gemma3_1b.html'>gemma3:1b</a></td>
<td>679</td>
<td>4875</td>
<td>21.704986375s</td>
<td>53.878083ms</td>
<td>370 token(s)</td>
<td>413.521583ms</td>
<td>894.75 tokens/s</td>
<td>1346 token(s)</td>
<td>21.236929292s</td>
<td>63.38 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./gemma3_4b.html'>gemma3:4b</a></td>
<td>568</td>
<td>4446</td>
<td>42.816239541s</td>
<td>52.300416ms</td>
<td>370 token(s)</td>
<td>1.363511s</td>
<td>271.36 tokens/s</td>
<td>1138 token(s)</td>
<td>41.399770583s</td>
<td>27.49 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./gemma_2b.html'>gemma:2b</a></td>
<td>182</td>
<td>1519</td>
<td>11.415126959s</td>
<td>29.6865ms</td>
<td>384 token(s)</td>
<td>656.551708ms</td>
<td>584.87 tokens/s</td>
<td>487 token(s)</td>
<td>10.728386375s</td>
<td>45.39 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./granite3_2_vision_2b.html'>granite3.2-vision:2b</a></td>
<td>177</td>
<td>1445</td>
<td>12.072434625s</td>
<td>15.315584ms</td>
<td>379 token(s)</td>
<td>1.858149792s</td>
<td>203.97 tokens/s</td>
<td>378 token(s)</td>
<td>10.196927291s</td>
<td>37.07 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./granite3_3_2b.html'>granite3.3:2b</a></td>
<td>202</td>
<td>1762</td>
<td>11.81480875s</td>
<td>12.089334ms</td>
<td>375 token(s)</td>
<td>1.022318875s</td>
<td>366.81 tokens/s</td>
<td>391 token(s)</td>
<td>10.779660334s</td>
<td>36.27 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./huihui_ai_baronllm_abliterated_8b.html'>huihui_ai/baronllm-abliterated:8b</a></td>
<td>200</td>
<td>2239</td>
<td>29.373928458s</td>
<td>28.82325ms</td>
<td>332 token(s)</td>
<td>2.649069666s</td>
<td>125.33 tokens/s</td>
<td>439 token(s)</td>
<td>26.695136792s</td>
<td>16.44 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./llama3_groq_tool_use_8b.html'>llama3-groq-tool-use:8b</a></td>
<td>165</td>
<td>1617</td>
<td>22.856236083s</td>
<td>28.823666ms</td>
<td>332 token(s)</td>
<td>3.020408833s</td>
<td>109.92 tokens/s</td>
<td>363 token(s)</td>
<td>19.805979959s</td>
<td>18.33 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./llama3_2_1b.html'>llama3.2:1b</a></td>
<td>338</td>
<td>3170</td>
<td>14.842241666s</td>
<td>27.571625ms</td>
<td>347 token(s)</td>
<td>367.021667ms</td>
<td>945.45 tokens/s</td>
<td>753 token(s)</td>
<td>14.447074333s</td>
<td>52.12 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./llava_llama3_8b.html'>llava-llama3:8b</a></td>
<td>407</td>
<td>3113</td>
<td>51.346792583s</td>
<td>29.816375ms</td>
<td>350 token(s)</td>
<td>4.136797292s</td>
<td>84.61 tokens/s</td>
<td>768 token(s)</td>
<td>47.17959975s</td>
<td>16.28 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./llava_phi3_3_8b.html'>llava-phi3:3.8b</a></td>
<td>211</td>
<td>2069</td>
<td>21.844198875s</td>
<td>17.263792ms</td>
<td>394 token(s)</td>
<td>2.039362125s</td>
<td>193.20 tokens/s</td>
<td>542 token(s)</td>
<td>19.786636083s</td>
<td>27.39 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./llava_7b.html'>llava:7b</a></td>
<td>286</td>
<td>2162</td>
<td>37.30128325s</td>
<td>14.302167ms</td>
<td>391 token(s)</td>
<td>3.116074125s</td>
<td>125.48 tokens/s</td>
<td>641 token(s)</td>
<td>34.170041834s</td>
<td>18.76 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./minicpm_v_8b.html'>minicpm-v:8b</a></td>
<td>208</td>
<td>2004</td>
<td>26.027833166s</td>
<td>26.347083ms</td>
<td>345 token(s)</td>
<td>2.888087709s</td>
<td>119.46 tokens/s</td>
<td>442 token(s)</td>
<td>23.111914041s</td>
<td>19.12 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./mistral_7b.html'>mistral:7b</a></td>
<td>320</td>
<td>2797</td>
<td>43.31221175s</td>
<td>9.55925ms</td>
<td>388 token(s)</td>
<td>2.9622185s</td>
<td>130.98 tokens/s</td>
<td>754 token(s)</td>
<td>40.33940675s</td>
<td>18.69 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./qwen2_5_coder_7b.html'>qwen2.5-coder:7b</a></td>
<td>429</td>
<td>3789</td>
<td>49.588974125s</td>
<td>27.604875ms</td>
<td>366 token(s)</td>
<td>3.235688541s</td>
<td>113.11 tokens/s</td>
<td>817 token(s)</td>
<td>46.325045375s</td>
<td>17.64 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./qwen2_5vl_3b.html'>qwen2.5vl:3b</a></td>
<td>6</td>
<td>43</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td class='left'><a href='./qwen2_5vl_7b.html'>qwen2.5vl:7b</a></td>
<td>423</td>
<td>3439</td>
<td>49.557716375s</td>
<td>41.111917ms</td>
<td>360 token(s)</td>
<td>3.589210541s</td>
<td>100.30 tokens/s</td>
<td>807 token(s)</td>
<td>45.926221125s</td>
<td>17.57 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./qwen3_1_7b.html'>qwen3:1.7b</a></td>
<td>6</td>
<td>43</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td class='left'><a href='./qwen3_8b.html'>qwen3:8b</a></td>
<td>6</td>
<td>43</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td class='left'><a href='./stable_code_3b.html'>stable-code:3b</a></td>
<td>152</td>
<td>1218</td>
<td>10.102081s</td>
<td>19.756084ms</td>
<td>371 token(s)</td>
<td>1.499911209s</td>
<td>247.35 tokens/s</td>
<td>339 token(s)</td>
<td>8.581758458s</td>
<td>39.50 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./starcoder_7b.html'>starcoder:7b</a></td>
<td>31</td>
<td>183</td>
<td>4.342161166s</td>
<td>9.639625ms</td>
<td>342 token(s)</td>
<td>2.140157125s</td>
<td>159.80 tokens/s</td>
<td>42 token(s)</td>
<td>2.191861166s</td>
<td>19.16 tokens/s</td>
</tr>
</table>
<br /><br />
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.3</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>14G + 3826M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p><a href='../index.html'>ollama-multirun</a>: <b>help_me_a_write_a_php_function_to_parse_data_from_</b>: 20250703-133310</p>
<p>Page created: 2025-07-03 14:14:12</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v5.7</p>
</footer></body></html>
