<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
  body { font-family: monospace; }
  textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
  header, footer { background-color: #f0f0f0; padding: 10px; }
  .menu { font-size: small; }
  table, td, th { border-collapse: collapse; }
  td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
  .left { text-align: left; }
  li { margin: 5px; }
</style><title>ollama multirun: dolphin3:8b</title></head><body>
<header><a href='../index.html'>ollama multirun</a>: <a href='./index.html'>__socrates_is_a_human___all_humans_are_mortal___</a>: <b>dolphin3:8b</b><br /><br />
<span class='menu'>models: 
<a href='./codellama:7b.html'>codellama:7b</a> 
<a href='./deepcoder:1.5b.html'>deepcoder:1.5b</a> 
<b>dolphin3:8b</b> 
<a href='./gemma:2b.html'>gemma:2b</a> 
<a href='./granite3.3:2b.html'>granite3.3:2b</a> 
<a href='./llama2-uncensored:7b.html'>llama2-uncensored:7b</a> 
<a href='./mistral:7b.html'>mistral:7b</a> 
<a href='./qwen2.5-coder:7b.html'>qwen2.5-coder:7b</a> 
<a href='./qwen3:1.7b.html'>qwen3:1.7b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./__socrates_is_a_human___all_humans_are_mortal___.prompt.yaml'>yaml</a>)
  words:14  bytes:70<br />
<textarea readonly rows='3'>- Socrates is a human.
- All humans are mortal.
- Is Socrates mortal?</textarea>
</p>
<p>Output: dolphin3:8b (<a href='./dolphin3:8b.txt'>raw</a>)  words:72  bytes:403<br />
<textarea readonly rows='6'>Yes, based on the given premises that all humans are mortal and Socrates is a human, it can be logically concluded that Socrates is mortal. This conclusion follows from a syllogism where the first premise states that all humans are mortal (All A are B), the second premise states that Socrates is human (S is A), and thus the conclusion derived from these premises is that Socrates is mortal (S is B).</textarea>
</p>
<p>Stats: dolphin3:8b (<a href='./dolphin3:8b.stats.txt'>raw</a>)<br />
<textarea readonly rows='9'>total duration:       26.378062004s
load duration:        5.225225741s
prompt eval count:    42 token(s)
prompt eval duration: 4.276776223s
prompt eval rate:     9.82 tokens/s
eval count:           89 token(s)
eval duration:        16.874203539s
eval rate:            5.27 tokens/s</textarea>
</p>
<p>ollama Model Info: <a target='ollama' href='https://ollama.com/library/dolphin3:8b'>dolphin3:8b</a></p>
<p>Created: 2025-05-31 21:47:08</p>
<footer><p>Generated with <a target='ollama multirun' href='https://github.com/attogram/ollama-multirun'>ollama multirun</a> v2.0</p></footer>
</body></html>
