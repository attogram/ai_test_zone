  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: stable-code:3b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>help_me_write_bash_function_to_parse_data_from_thi</a>: <b>stable-code:3b</b>: 20250609-151056<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./qwen2.5-coder:7b.html'>qwen2.5-coder:7b</a> 
<a href='./codellama:7b.html'>codellama:7b</a> 
<a href='./starcoder:7b.html'>starcoder:7b</a> 
<b>stable-code:3b</b> 
<a href='./deepcoder:1.5b.html'>deepcoder:1.5b</a> 
<a href='./dolphin3:8b.html'>dolphin3:8b</a> 
<a href='./gemma:2b.html'>gemma:2b</a> 
<a href='./granite3.3:2b.html'>granite3.3:2b</a> 
<a href='./mistral:7b.html'>mistral:7b</a> 
<a href='./qwen3:1.7b.html'>qwen3:1.7b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./help_me_write_bash_function_to_parse_data_from_thi.prompt.yaml'>yaml</a>)
  words:174  bytes:1514<br />
<textarea readonly rows='10'>Help me write bash function to parse data from this model.info.txt file:

- in the Model section, each line is in format &quot;name    value&quot;
  - for each line, save as bash variable: name=&quot;$value&quot; 
  - example:  line &quot;architecture        granite&quot; parses to: architecture=&quot;granite&quot;
 
- in the Capabilities section, each line is a single keyword
  - save all the keywords into a bash array

- in the System section, single or multiple lines showing the system prompt
  - save as var $systemPrompt

- In the Parameters section (has same format as Model section)
  - only save the &#39;temperature&#39; value

- Allow that any section or any line may be missing

example model.info.txt contents:

  Model
    architecture        granite    
    parameters          2.5B       
    context length      16384      
    embedding length    2048       
    quantization        Q4_K_M     

  Capabilities
    completion    
    tools         
    vision        

  Projector
    architecture        clip       
    parameters          441.86M    
    embedding length    1152       
    dimensions          0          

  Parameters
    num_ctx        16384    
    temperature    0        

  System
    A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful,    
      detailed, and polite answers to the user&#39;s questions.                                                   

  License
    Apache License               
    Version 2.0, January 2004    
    ...                          </textarea>
</p>
<p>Output: stable-code:3b (<a href='./stable-code:3b.txt'>raw</a>)<br />
<textarea readonly rows='25'>Here&#39;s a Bash script that can parse data from the given `model.info.txt` file:

```bash
#!/bin/bash

parse_model() {
  local filename=&quot;$1&quot;
  while IFS= read -r line || [[ -n &quot;$line&quot; ]]; do
    name=$(echo $line | awk &#39;{print $2}&#39;)
    value=$(echo $line | awk &#39;{print $4}&#39;)
    if [[ -n &quot;$name&quot; &amp;&amp; -n &quot;$value&quot; ]]; then
      eval &quot;${name}=${value}&quot;
    fi
  done &lt; &quot;$filename&quot;
}

parse_capabilities() {
  local filename=&quot;$1&quot;
  IFS=$&#39;\n&#39; read -r -d &#39;&#39; capabilities &lt;&lt; EOF
$(&lt;&quot;$filename&quot; | tr &#39; &#39; &#39;\n&#39; | grep -v &#39;^$&#39;)
EOF
  echo &quot;${capabilities[@]]&quot;
}

parse_system() {
  local filename=&quot;$1&quot;
  IFS=$&#39;\n&#39; read -r -d &#39;&#39; systemPrompt &lt;&lt; EOF
$(&lt;&quot;$filename&quot; | tr &#39; &#39; &#39;\n&#39; | grep -v &#39;^$&#39;)
EOF
  echo &quot;$systemPrompt&quot;
}

parse_parameters() {
  local filename=&quot;$1&quot;
  IFS=$&#39;\n&#39; read -r -d &#39;&#39; params &lt;&lt; EOF
$(&lt;&quot;$filename&quot; | tr &#39; &#39; &#39;\n&#39; | grep -v &#39;^$&#39;)
EOF
  eval &quot;${params[@]}&quot;
}

# Parse the input file based on its section and content type.
parse_model &quot;$1&quot;
parse_capabilities &quot;$1&quot;
parse_system &quot;$1&quot;
parse_parameters &quot;$1&quot;
```

This script defines functions for parsing each section of the input file. The `parse_*()` functions read the contents of the input file, parse it based on its section and content type, and save the parsed data into appropriate variables or arrays. Finally, the parsed data is printed out for further processing or displaying to the user.</textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./stable-code:3b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>213</td></tr>
<tr><td class='left'>bytes</td><td>1355</td></tr>
<tr><td class='left'>total duration</td><td>14.397587792s</td></tr>
<tr><td class='left'>load duration</td><td>1.323059792s</td></tr>
<tr><td class='left'>prompt eval count</td><td>370 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>1.549243083s</td></tr>
<tr><td class='left'>prompt eval rate</td><td>238.83 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>450 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>11.5248545s</td></tr>
<tr><td class='left'>eval rate</td><td>39.05 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./stable-code:3b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/stable-code:3b'>stable-code:3b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>stablelm</td></tr>
<tr><td class='left'>size</td><td class='left'>2.8 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>2.8B</td></tr>
<tr><td class='left'>context length</td><td class='left'>16384</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>2560</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q4_0</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>11G + 812M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p>page created:   2025-06-09 15:12:39</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v4.2</p>
</footer></body></html>
