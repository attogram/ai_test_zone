[PYTHON]
# This script is meant to be run as a Python module, not a standalone script.
# It is importing other scripts that are assumed to be in the same directory.

import sys

from ollama import __version__, clear_loaded_models, load_model
from prompt import get_prompt

def main():
    model = sys.argv[1]
    prompt = get_prompt()

    # Load the model into Ollama
    load_model(model)

    # Run the model with the given prompt
    output = ollama.run(model, prompt)

    # Print the output
    print(output)

    # Clear the loaded models from Ollama
    clear_loaded_models()

if __name__ == "__main__":
    main()
[/PYTHON]
[TESTS]
# Test that the script can be run as a Python module
import sys
sys.path.append('./')
from ollama import __version__

def test_ollama_version():
    assert __version__ == "0.1.0"

# Test that the script can load a model and run it with a prompt
import os
import pytest
from ollama import clear_loaded_models, load_model
from prompt import get_prompt

@pytest.fixture(scope="module")
def model():
    return "tests/fixtures/hello.txt"

def test_load_model(model):
    assert os.path.isfile(model)
    load_model(model)

def test_get_prompt():
    prompt = get_prompt()
    assert prompt == "Hello, Ollama!"

def test_run_model(model):
    output = ollama.run(model, prompt)
    assert output == "Hello, Ollama!"

def test_clear_loaded_models():
    clear_loaded_models()
    assert len(ollama.get_loaded_models()) == 0

# Test that the script can load multiple models and run them with a prompt
import os
from ollama import clear_loaded_models, load_model
from prompt import get_prompt

def test_load_multiple_models():
    model1 = "tests/fixtures/hello.txt"
    model2 = "tests/fixtures/greeting.txt"
    assert os.path.isfile(model1)
    assert os.path.isfile(model2)
    load_model(model1)
    load_model(model2)

def test_get_prompt():
    prompt = get_prompt()
    assert prompt == "Hello, Ollama!"

def test_run_multiple_models(model):
    output = ollama.run(model1, prompt)
    assert output == "Hello, Ollama!"
    output = ollama.run(model2, prompt)
    assert output == "Greetings, Ollama!"

def test_clear_loaded_models():
    clear_loaded_models()
    assert len(ollama.get_loaded_models()) == 0
[/TESTS]


