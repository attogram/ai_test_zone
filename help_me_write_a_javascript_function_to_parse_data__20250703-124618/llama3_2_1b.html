  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: llama3.2:1b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>help_me_write_a_javascript_function_to_parse_data_</a>: <b>llama3.2:1b</b>: 20250703-124618<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./bakllava_7b.html'>bakllava:7b</a> 
<a href='./codellama_7b.html'>codellama:7b</a> 
<a href='./deepcoder_1_5b.html'>deepcoder:1.5b</a> 
<a href='./deepseek_r1_1_5b.html'>deepseek-r1:1.5b</a> 
<a href='./deepseek_r1_8b.html'>deepseek-r1:8b</a> 
<a href='./dolphin_mistral_7b.html'>dolphin-mistral:7b</a> 
<a href='./dolphin3_8b.html'>dolphin3:8b</a> 
<a href='./gemma3_1b.html'>gemma3:1b</a> 
<a href='./gemma3_4b.html'>gemma3:4b</a> 
<a href='./gemma_2b.html'>gemma:2b</a> 
<a href='./granite3_2_vision_2b.html'>granite3.2-vision:2b</a> 
<a href='./granite3_3_2b.html'>granite3.3:2b</a> 
<a href='./huihui_ai_baronllm_abliterated_8b.html'>huihui_ai/baronllm-abliterated:8b</a> 
<a href='./llama3_groq_tool_use_8b.html'>llama3-groq-tool-use:8b</a> 
<b>llama3.2:1b</b> 
<a href='./llava_llama3_8b.html'>llava-llama3:8b</a> 
<a href='./llava_phi3_3_8b.html'>llava-phi3:3.8b</a> 
<a href='./llava_7b.html'>llava:7b</a> 
<a href='./minicpm_v_8b.html'>minicpm-v:8b</a> 
<a href='./mistral_7b.html'>mistral:7b</a> 
<a href='./qwen2_5_coder_7b.html'>qwen2.5-coder:7b</a> 
<a href='./qwen2_5vl_3b.html'>qwen2.5vl:3b</a> 
<a href='./qwen2_5vl_7b.html'>qwen2.5vl:7b</a> 
<a href='./qwen3_1_7b.html'>qwen3:1.7b</a> 
<a href='./qwen3_8b.html'>qwen3:8b</a> 
<a href='./stable_code_3b.html'>stable-code:3b</a> 
<a href='./starcoder_7b.html'>starcoder:7b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./help_me_write_a_javascript_function_to_parse_data_.prompt.yaml'>yaml</a>)
  words:176  bytes:1510<br />
<textarea readonly rows='10'>Help me write a Javascript function to parse data from this model.info.txt file:

- in the Model section, each line is in format &quot;name    value&quot;
  - for each line, save as a javascript variable: name=&quot;$value&quot; 
  - example:  line &quot;architecture        granite&quot; parses to: architecture=&quot;granite&quot;
 
- in the Capabilities section, each line is a single keyword
  - save all the keywords into a javascript array

- in the System section, single or multiple lines showing the system prompt
  - save as var $systemPrompt

- In the Parameters section (has same format as Model section)
  - only save the &#39;temperature&#39; value

- Allow that any section or any line may be missing

example model.info.txt contents:

  Model
    architecture        granite    
    parameters          2.5B       
    context length      16384      
    embedding length    2048       
    quantization        Q4_K_M     

  Capabilities
    completion    
    tools         
    vision        

  Projector
    architecture        clip       
    parameters          441.86M    
    embedding length    1152       
    dimensions          0          

  Parameters
    num_ctx        16384    
    temperature    0        

  System
    A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful,    
      detailed, and polite answers to the user&#39;s questions.                                                   

  License
    Apache License               
    Version 2.0, January 2004    
    ...</textarea>
</p>
<p>Output: llama3.2:1b (<a href='./llama3_2_1b.output.txt'>raw</a>)<br />
<textarea readonly rows='25'>Here is a well-structured JavaScript function that parses the `model.info.txt` file according to your specifications:
```javascript
const fs = require(&#39;fs&#39;);

function parseModelInfo(filename) {
  const parsedData = {};

  try {
    const dataContent = fs.readFileSync(filename, &#39;utf8&#39;);
    const lines = dataContent.split(&#39;\n&#39;);

    // Model section
    const modelLines = lines.filter(line =&gt; line.trim().startsWith(&#39;Model&#39;));
    for (const line of modelLines) {
      const parts = line.split(/\s+/);
      if (parts.length !== 2 || !parts[1].trim()) continue;
      parsedData[`$${parts[0]}`] = parts[1].trim();
    }

    // Capabilities section
    const capabilitiesLines = lines.filter(line =&gt; line.trim().startsWith(&#39;Capabilities&#39;));
    for (const line of capabilitiesLines) {
      if (!line || !line.trim()) continue;
      parsedData[&#39;$capabilities&#39;] = line.trim();
    }

    // System section
    const systemPromptLines = lines.filter(line =&gt; line.trim().startsWith(&#39;$systemPrompt&#39;));
    for (const line of systemPromptLines) {
      if (!line || !line.trim()) continue;
      parsedData[`$systemPrompt`] = line.trim();
    }

    // Parameters section
    const parametersLines = lines.filter(line =&gt; line.trim().includes(&#39;parameters&#39;));
    for (const line of parametersLines) {
      if (!line || !line.trim() || !line.includes(&#39;temperature&#39;)) continue;
      parsedData[&#39;temperature&#39;] = line.trim();
    }

  } catch (error) {
    console.error(`Error parsing model info file: ${error}`);
  }

  return parsedData;
}
```
You can use this function like this:
```javascript
const parsedData = parseModelInfo(&#39;model.info.txt&#39;);
console.log(parsedData);
```
This will output the parsed data in a JavaScript object, with the following structure:
```javascript
{
  &quot;$Model&quot;: &quot;granite&quot;,
  &quot;$Capabilities&quot;: &quot;completion tools vision&quot;,
  &quot;$SystemPrompt&quot;: &quot;A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#39;s questions.&quot;
}
```
Note that this implementation assumes that the input file is in the correct format, with each line following the specified structure. If you need to handle edge cases or errors, you may want to add additional checks and error handling.</textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./llama3_2_1b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>259</td></tr>
<tr><td class='left'>bytes</td><td>2269</td></tr>
<tr><td class='left'>total duration</td><td>10.204498s</td></tr>
<tr><td class='left'>load duration</td><td>30.595333ms</td></tr>
<tr><td class='left'>prompt eval count</td><td>346 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>430.363541ms</td></tr>
<tr><td class='left'>prompt eval rate</td><td>803.97 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>506 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>9.742847834s</td></tr>
<tr><td class='left'>eval rate</td><td>51.94 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./llama3_2_1b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/llama3.2:1b'>llama3.2:1b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>llama</td></tr>
<tr><td class='left'>size</td><td class='left'>2.8 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>1.2B</td></tr>
<tr><td class='left'>context length</td><td class='left'>131072</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>2048</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q8_0</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br />tools<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.3</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>13G + 1919M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>help_me_write_a_javascript_function_to_parse_data_</a>: <b>llama3.2:1b</b>: 20250703-124618</p>
<p>Page created: 2025-07-03 13:00:35</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v5.7</p>
</footer></body></html>
