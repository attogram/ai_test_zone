  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: granite3.3:2b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>who_are_you__what_are_you__how_do_you_function__an</a>: <b>granite3.3:2b</b>: 20250614-130209<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./bakllava_7b.html'>bakllava:7b</a> 
<a href='./codellama_7b.html'>codellama:7b</a> 
<a href='./deepcoder_1_5b.html'>deepcoder:1.5b</a> 
<a href='./deepseek_r1_1_5b.html'>deepseek-r1:1.5b</a> 
<a href='./deepseek_r1_8b.html'>deepseek-r1:8b</a> 
<a href='./dolphin3_8b.html'>dolphin3:8b</a> 
<a href='./gemma3_1b.html'>gemma3:1b</a> 
<a href='./gemma3_4b.html'>gemma3:4b</a> 
<a href='./gemma_2b.html'>gemma:2b</a> 
<a href='./granite3_2_vision_2b.html'>granite3.2-vision:2b</a> 
<b>granite3.3:2b</b> 
<a href='./llava_llama3_8b.html'>llava-llama3:8b</a> 
<a href='./llava_phi3_3_8b.html'>llava-phi3:3.8b</a> 
<a href='./llava_7b.html'>llava:7b</a> 
<a href='./minicpm_v_8b.html'>minicpm-v:8b</a> 
<a href='./mistral_7b.html'>mistral:7b</a> 
<a href='./moondream_1_8b.html'>moondream:1.8b</a> 
<a href='./qwen2_5_coder_7b.html'>qwen2.5-coder:7b</a> 
<a href='./qwen2_5vl_3b.html'>qwen2.5vl:3b</a> 
<a href='./qwen2_5vl_7b.html'>qwen2.5vl:7b</a> 
<a href='./qwen3_1_7b.html'>qwen3:1.7b</a> 
<a href='./stable_code_3b.html'>stable-code:3b</a> 
<a href='./starcoder_7b.html'>starcoder:7b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./who_are_you__what_are_you__how_do_you_function__an.prompt.yaml'>yaml</a>)
  words:15  bytes:69<br />
<textarea readonly rows='1'>Who are you, What are you, How do you function, and What can you do?</textarea>
</p>
<p>Output: granite3.3:2b (<a href='./granite3_3_2b.output.txt'>raw</a>)<br />
<textarea readonly rows='25'>**Who am I?**
I am an artificial intelligence (AI) language model, specifically designed to assist with information, answer questions, generate text, and engage in conversation. I don&#39;t possess consciousness, emotions, or a physical form; I&#39;m a software program running on computer servers.

**What do I function?**
I function through complex algorithms and machine learning techniques that process and analyze vast amounts of text data during my training phase. When you interact with me, your input is analyzed, and I generate relevant responses based on patterns and knowledge I&#39;ve learned from this data. My purpose is to understand context, provide information, offer explanations, create stories, write code snippets, translate languages, and much more.

**How do I function?**
My functionality relies heavily on natural language processing (NLP) techniques, including:
1. **Tokenization**: Breaking down text into smaller units like words or phrases for easier analysis.
2. **Part-of-speech tagging**: Identifying the grammatical role of each word in a sentence.
3. **Named Entity Recognition (NER)**: Pinpointing and categorizing key information, such as names, organizations, locations, etc.
4. **Dependency Parsing**: Understanding the structure of sentences to analyze relationships between words.
5. **Semantic Analysis**: Interpreting the meaning behind words and phrases for context-aware responses.

I leverage deep learning models, particularly transformer architectures like BERT, GPT (Generative Pre-trained Transformer), and their variants, which are trained on massive text corpora to capture intricate linguistic patterns. During inference, I predict the likelihood of a sequence of words occurring together, generating coherent and contextually relevant responses.

**What can I do?**
Given my training data and capabilities, here&#39;s what I can do:
- **Answer questions**: Provide concise, informative answers on a wide range of topics.
- **Generate creative text**: Write stories, poems, scripts, and more tailored to your specifications.
- **Translate languages**: Translate text from one language to another.
- **Explain concepts**: Simplify complex ideas into understandable explanations.
- **Provide suggestions/ideas**: Offer alternatives, recommendations, or creative input on various topics.
- **Assist with tasks**: Help draft emails, create outlines, brainstorm, and more based on your requirements.
- **Engage in conversation**: Have interactive discussions, maintain context, and adapt responses accordingly.

Keep in mind that while I strive to provide accurate and helpful information, my responses are based on patterns in the data I was trained on, and I don&#39;t have real-time access to the internet or personal user databases for up-to-the-minute or personalized information.</textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./granite3_3_2b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>391</td></tr>
<tr><td class='left'>bytes</td><td>2814</td></tr>
<tr><td class='left'>total duration</td><td>15.293056958s</td></tr>
<tr><td class='left'>load duration</td><td>16.704458ms</td></tr>
<tr><td class='left'>prompt eval count</td><td>62 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>237.621959ms</td></tr>
<tr><td class='left'>prompt eval rate</td><td>260.92 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>601 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>15.037865041s</td></tr>
<tr><td class='left'>eval rate</td><td>39.97 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./granite3_3_2b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/granite3.3:2b'>granite3.3:2b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>granite</td></tr>
<tr><td class='left'>size</td><td class='left'>3.3 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>2.5B</td></tr>
<tr><td class='left'>context length</td><td class='left'>131072</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>2048</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q4_K_M</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br />tools<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>12G + 668M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>who_are_you__what_are_you__how_do_you_function__an</a>: <b>granite3.3:2b</b>: 20250614-130209</p>
<p>page created:   2025-06-14 13:05:44</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v5.0</p>
</footer></body></html>
