  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: codellama:7b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>you_are_helping_me_update_a_bash_script_we_have_2</a>: <b>codellama:7b</b>: 20250609-152046<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./qwen2.5-coder:7b.html'>qwen2.5-coder:7b</a> 
<b>codellama:7b</b> 
<a href='./starcoder:7b.html'>starcoder:7b</a> 
<a href='./stable-code:3b.html'>stable-code:3b</a> 
<a href='./deepcoder:1.5b.html'>deepcoder:1.5b</a> 
<a href='./dolphin3:8b.html'>dolphin3:8b</a> 
<a href='./gemma:2b.html'>gemma:2b</a> 
<a href='./granite3.3:2b.html'>granite3.3:2b</a> 
<a href='./mistral:7b.html'>mistral:7b</a> 
<a href='./qwen3:1.7b.html'>qwen3:1.7b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./you_are_helping_me_update_a_bash_script_we_have_2.prompt.yaml'>yaml</a>)
  words:174  bytes:1238<br />
<textarea readonly rows='10'>You are helping me update a bash script.
We have 2 text files: stats.txt and show.txt.

Read in and parse the stats file:
  - save the data into bash variables
  - each line is in format &quot;name: value&quot;
  - for example line:
    total duration:       4.687657458s
 - is parsed so we can get the name &quot;total duration&quot; and the value &quot;4.687657458s&quot;
 - Example stats.txt file:
&#39;&#39;&#39;
total duration:       4.687657458s
load duration:        1.174041625s
prompt eval count:    22 token(s)
prompt eval duration: 152.612625ms
prompt eval rate:     144.16 tokens/s
eval count:           209 token(s)
eval duration:        3.360331625s
eval rate:            62.20 tokens/s

&#39;&#39;&#39;

Read in a parse the show.txt file:
  - save the data into bash variables
  - There are 3 sections: Model, Capabilities, and Parameters
  - For Model Section, it&#39;s in format &quot;name   value&quot;
  - For Capabilities section, it&#39;s a list of 1 or more words
  - For Parameters section, it&#39;s in format &quot;name   value&quot;
  - Example show.txt file:
&#39;&#39;&#39;
  Model
    architecture        starcoder
    parameters          7.5B
    context length      8192
    embedding length    4096
    quantization        Q4_0

  Capabilities
    completion

  Parameters
    stop    &quot;&lt;|endoftext|&gt;&quot;
&#39;&#39;&#39;</textarea>
</p>
<p>Output: codellama:7b (<a href='./codellama:7b.txt'>raw</a>)<br />
<textarea readonly rows='25'>
To parse the data in the `stats.txt` file, you can use the following code:
```bash
#!/bin/bash

# Read in the stats file
while read -r line; do
  # Split the line into name and value using the &quot;:&quot; character as the delimiter
  IFS=&#39;:&#39;; read -ra parts &lt;&lt;&lt; &quot;$line&quot;
  # Set the variable for the name to the first part of the split, and the variable for the value to the second part
  name=${parts[0]}
  value=${parts[1]}
  # Save the data into bash variables
  eval &quot;$name=$value&quot;
done &lt; stats.txt
```
This code uses the `read` command with the `-a` option to store the output in an array, and then sets the variable for the name using the first element of the array, and the variable for the value using the second element. The `eval` command is used to set the variables in the shell environment.

To parse the data in the `show.txt` file, you can use a similar approach:
```bash
#!/bin/bash

# Read in the show file
while read -r line; do
  # Split the line into name and value using the &quot;:&quot; character as the delimiter
  IFS=&#39;:&#39;; read -ra parts &lt;&lt;&lt; &quot;$line&quot;
  # Set the variable for the name to the first part of the split, and the variable for the value to the second part
  name=${parts[0]}
  value=${parts[1]}
  # Save the data into bash variables
  eval &quot;$name=$value&quot;
done &lt; show.txt
```
This code uses the `read` command with the `-a` option to store the output in an array, and then sets the variable for the name using the first element of the array, and the variable for the value using the second element. The `eval` command is used to set the variables in the shell environment.

You can then access the data in the bash variables using the syntax `${variable_name}`. For example, if you have a variable named `total_duration` with a value of `4.687657458s`, you can access it using the syntax `${total_duration}` or `$total_duration`.</textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./codellama:7b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>322</td></tr>
<tr><td class='left'>bytes</td><td>1847</td></tr>
<tr><td class='left'>total duration</td><td>33.55576875s</td></tr>
<tr><td class='left'>load duration</td><td>2.830724083s</td></tr>
<tr><td class='left'>prompt eval count</td><td>443 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>3.395268833s</td></tr>
<tr><td class='left'>prompt eval rate</td><td>130.48 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>503 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>27.328808875s</td></tr>
<tr><td class='left'>eval rate</td><td>18.41 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./codellama:7b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/codellama:7b'>codellama:7b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>llama</td></tr>
<tr><td class='left'>size</td><td class='left'>9.4 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>6.7B</td></tr>
<tr><td class='left'>context length</td><td class='left'>16384</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>4096</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q4_0</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>10G + 1745M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p>page created:   2025-06-09 15:22:31</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v4.2</p>
</footer></body></html>
