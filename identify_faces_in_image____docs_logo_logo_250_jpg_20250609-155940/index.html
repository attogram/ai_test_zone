  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: identify_faces_in_image____docs_logo_logo_250_jpg</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <b>identify_faces_in_image____docs_logo_logo_250_jpg</b>: 20250609-155940<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./granite3.2-vision:2b.html'>granite3.2-vision:2b</a> 
<a href='./minicpm-v:8b.html'>minicpm-v:8b</a> 
<a href='./qwen2.5vl:3b.html'>qwen2.5vl:3b</a> 
<a href='./qwen2.5vl:7b.html'>qwen2.5vl:7b</a> 
<a href='./gemma3:4b.html'>gemma3:4b</a> 
<a href='./llava:7b.html'>llava:7b</a> 
<a href='./llava-llama3:8b.html'>llava-llama3:8b</a> 
<a href='./llava-phi3:3.8b.html'>llava-phi3:3.8b</a> 
<a href='./bakllava:7b.html'>bakllava:7b</a> 
<a href='./moondream:1.8b.html'>moondream:1.8b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./identify_faces_in_image____docs_logo_logo_250_jpg.prompt.yaml'>yaml</a>)
  words:27  bytes:174<br />
<textarea readonly rows='5'>
Identify faces in image: ./docs/logo/logo-250.jpg
Find faces of people or animals
Tell the bounding box dimensions: top left x,y and bottom right x,y
Respond in JSON format</textarea>
</p>
<div class='box'><a target='image' href='logo-250.jpg'><img src='logo-250.jpg' alt='./docs/logo/logo-250.jpg' width='250' /></a></div><br />
<table>
  <tr>
    <th class='left'>model</th>
    <th>words</th>
    <th>bytes</th>
    <th>total<br />duration</th>
    <th>load<br />duration</th>
    <th>prompt eval<br />count</th>
    <th>prompt eval<br />duration</th>
    <th>prompt eval<br />rate</th>
    <th>eval<br />count</th>
    <th>eval<br />duration</th>
    <th>eval<br />rate</th>
  </tr>
<tr>
<td class='left'><a href='./granite3.2-vision:2b.html'>granite3.2-vision:2b</a></td>
<td>183</td>
<td>1134</td>
<td>30.249530917s</td>
<td>2.094122334s</td>
<td>2274 token(s)</td>
<td>18.103386042s</td>
<td>125.61 tokens/s</td>
<td>242 token(s)</td>
<td>10.0475055s</td>
<td>24.09 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./minicpm-v:8b.html'>minicpm-v:8b</a></td>
<td>96</td>
<td>635</td>
<td>18.530966834s</td>
<td>3.447901625s</td>
<td>107 token(s)</td>
<td>6.25742425s</td>
<td>17.10 tokens/s</td>
<td>182 token(s)</td>
<td>8.823089708s</td>
<td>20.63 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./qwen2.5vl:3b.html'>qwen2.5vl:3b</a></td>
<td>23</td>
<td>214</td>
<td>6.502880708s</td>
<td>2.090702291s</td>
<td>144 token(s)</td>
<td>2.403483125s</td>
<td>59.91 tokens/s</td>
<td>76 token(s)</td>
<td>2.007282458s</td>
<td>37.86 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./qwen2.5vl:7b.html'>qwen2.5vl:7b</a></td>
<td>26</td>
<td>166</td>
<td>11.3048s</td>
<td>2.838662833s</td>
<td>144 token(s)</td>
<td>4.253386208s</td>
<td>33.86 tokens/s</td>
<td>81 token(s)</td>
<td>4.211236584s</td>
<td>19.23 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./gemma3:4b.html'>gemma3:4b</a></td>
<td>37</td>
<td>322</td>
<td>49.878942083s</td>
<td>1.888967958s</td>
<td>306 token(s)</td>
<td>42.734207291s</td>
<td>7.16 tokens/s</td>
<td>153 token(s)</td>
<td>5.254036084s</td>
<td>29.12 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./llava:7b.html'>llava:7b</a></td>
<td>87</td>
<td>875</td>
<td>30.099750458s</td>
<td>2.8097925s</td>
<td>627 token(s)</td>
<td>3.993638083s</td>
<td>157.00 tokens/s</td>
<td>436 token(s)</td>
<td>23.295087667s</td>
<td>18.72 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./llava-llama3:8b.html'>llava-llama3:8b</a></td>
<td>4</td>
<td>25</td>
<td>9.607518167s</td>
<td>3.7401575s</td>
<td>624 token(s)</td>
<td>4.680783583s</td>
<td>133.31 tokens/s</td>
<td>21 token(s)</td>
<td>1.184044625s</td>
<td>17.74 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./llava-phi3:3.8b.html'>llava-phi3:3.8b</a></td>
<td>46</td>
<td>333</td>
<td>11.440384541s</td>
<td>2.112980458s</td>
<td>629 token(s)</td>
<td>2.871849583s</td>
<td>219.02 tokens/s</td>
<td>183 token(s)</td>
<td>6.454540334s</td>
<td>28.35 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./bakllava:7b.html'>bakllava:7b</a></td>
<td>4</td>
<td>25</td>
<td>8.103250542s</td>
<td>2.847930625s</td>
<td>631 token(s)</td>
<td>4.06435975s</td>
<td>155.25 tokens/s</td>
<td>24 token(s)</td>
<td>1.189737167s</td>
<td>20.17 tokens/s</td>
</tr>
<tr>
<td class='left'><a href='./moondream:1.8b.html'>moondream:1.8b</a></td>
<td>4</td>
<td>28</td>
<td>6.781485375s</td>
<td>1.595833875s</td>
<td>777 token(s)</td>
<td>4.886562584s</td>
<td>159.01 tokens/s</td>
<td>19 token(s)</td>
<td>295.098125ms</td>
<td>64.39 tokens/s</td>
</tr>
</table>
<br /><br />
<table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td>arm64</td></tr>
<tr><td class='left'>sys processor</td><td>arm</td></tr>
<tr><td class='left'>sys memory</td><td>12G + 2285M</td></tr>
<tr><td class='left'>sys OS</td><td>Darwin 24.5.0</td></tr>
</table>
<br /><br />
<footer>
<p>page created:   2025-06-09 16:02:52</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v4.2</p>
</footer></body></html>
