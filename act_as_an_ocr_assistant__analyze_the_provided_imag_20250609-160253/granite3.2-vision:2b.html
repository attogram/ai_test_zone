  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: granite3.2-vision:2b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>act_as_an_ocr_assistant__analyze_the_provided_imag</a>: <b>granite3.2-vision:2b</b>: 20250609-160253<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<b>granite3.2-vision:2b</b> 
<a href='./minicpm-v:8b.html'>minicpm-v:8b</a> 
<a href='./qwen2.5vl:3b.html'>qwen2.5vl:3b</a> 
<a href='./qwen2.5vl:7b.html'>qwen2.5vl:7b</a> 
<a href='./gemma3:4b.html'>gemma3:4b</a> 
<a href='./llava:7b.html'>llava:7b</a> 
<a href='./llava-llama3:8b.html'>llava-llama3:8b</a> 
<a href='./llava-phi3:3.8b.html'>llava-phi3:3.8b</a> 
<a href='./bakllava:7b.html'>bakllava:7b</a> 
<a href='./moondream:1.8b.html'>moondream:1.8b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./act_as_an_ocr_assistant__analyze_the_provided_imag.prompt.yaml'>yaml</a>)
  words:57  bytes:376<br />
<textarea readonly rows='9'>Act as an OCR assistant. Analyze the provided image and:

1. Recognize all visible text in the image as accurately as possible.
2. Maintain the original structure and formatting of the text.
3. If any words or phrases are unclear, indicate this with [unclear] in your transcription.

Provide only the transcription without any additional comments.

Image: ./docs/run.page.png</textarea>
</p>
<div class='box'><a target='image' href='run.page.png'><img src='run.page.png' alt='./docs/run.page.png' width='250' /></a></div><br /><p>Output: granite3.2-vision:2b (<a href='./granite3.2-vision:2b.txt'>raw</a>)<br />
<textarea readonly rows='22'>
```
olama_multirun: my hovercraft is full of eels
models: codellama:7b deepcoder:1.5b dolphin3:8b gemma:2b llama2-uncensored:7b mistrat:7b
Prompt: (raw) (yaml) words:6 bytes:30
My hovercraft is full of eels

model
words bytes total duration load prompt eval prompt eval count duration rate eval count duration rate
codellama:7b 16 85 11.387706433s 5.570671836s 28 token(s) 2.234853301s 12.53 tokens/s 25 token(s) 3.580512222s 6.98 tokens/s
deepcoder:1.5b 69 541 7.290153172s 1.718311435s 11 token(s) 154.603241ms 71.15 tokens/s 117 token(s) 5.416341396s 21.60 tokens/s
dolphin3:8b 50 271 20.453919063s 5.466473104s 31 token(s) 3.572317869s 8.68 tokens/s 62 token(s) 11.413612053s 5.43 tokens/s
gemma:2b 24 136 5.021592452s 2.958685413s 29 token(s) 3.941697440s 32.27 tokens/s 32 token(s) 15.17 tokens/s
granite3:3:2b 62 354 8.710353176s 1.611366493s 51 token(s) 1.139311546s 44.76 tokens/s 91 token(s) 5.957641006s 15.27 tokens/s
llama2-uncensored:7b 21 109 11.636989914s 5.324918521s 30 token(s) 2.35815667s 12.72 tokens/s 27 token(s) 3.95231728s 6.83 tokens/s
mistrat:7b 88 516 25.830198391s 3.925961498s 13 token(s) 1.652594407s 78.87 tokens/s 123 token(s) 20.249769203s 6.07 tokens/s
gwen2.5-coder:7b 64 376 22.007981457s 4.621085101s 37 token(s) 3.845300944s 96.62 tokens/s 75 token(s) 13.539761277s 5.54 tokens/s
gwen3.1.7b 569 3447 47.333980943s 2.204033628s 16 token(s) 240.671045ms 66.48 tokens/s 802 token(s) 44.887396975s 17.87 tokens/s
```</textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./granite3.2-vision:2b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>178</td></tr>
<tr><td class='left'>bytes</td><td>1454</td></tr>
<tr><td class='left'>total duration</td><td>2m54.984191292s</td></tr>
<tr><td class='left'>load duration</td><td>2.09318675s</td></tr>
<tr><td class='left'>prompt eval count</td><td>8153 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>1m18.526719667s</td></tr>
<tr><td class='left'>prompt eval rate</td><td>103.82 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>996 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>1m34.353279875s</td></tr>
<tr><td class='left'>eval rate</td><td>10.56 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./granite3.2-vision:2b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/granite3.2-vision:2b'>granite3.2-vision:2b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>granite</td></tr>
<tr><td class='left'>size</td><td class='left'>7.6 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>2.5B</td></tr>
<tr><td class='left'>context length</td><td class='left'>16384</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>2048</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q4_K_M</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br />tools<br />vision<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>12G + 2029M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p>page created:   2025-06-09 16:05:51</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v4.2</p>
</footer></body></html>
