  <!DOCTYPE html>
  <html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    a:hover { background-color: yellow; color: black; }
    body { font-family: monospace; }
    header, footer { background-color: #f0f0f0; padding: 10px; }
    li { margin: 5px; }
    table, td, th { border-collapse: collapse; }
    td, th { border: 1px solid #cccccc; padding: 5px; text-align: right; }
    tr:hover { background-color: lightyellow; color: black; }
    textarea { border: 1px solid #cccccc; white-space: pre-wrap; width: 90%; }
    .box { display: inline-block; margin: 3px; padding: 2px; vertical-align: top; }
    .left { text-align: left; }
    .menu { font-size: small; }
  </style>
<title>ollama-multirun: qwen2.5vl:3b</title></head><body>
<header><a href='../index.html'>ollama-multirun</a>: <a href='./index.html'>act_as_an_ocr_assistant__analyze_the_provided_imag</a>: <b>qwen2.5vl:3b</b>: 20250609-160253<br /><br />
<span class='menu'>
<a href='models.html'>models</a>: 
<a href='./granite3.2-vision:2b.html'>granite3.2-vision:2b</a> 
<a href='./minicpm-v:8b.html'>minicpm-v:8b</a> 
<b>qwen2.5vl:3b</b> 
<a href='./qwen2.5vl:7b.html'>qwen2.5vl:7b</a> 
<a href='./gemma3:4b.html'>gemma3:4b</a> 
<a href='./llava:7b.html'>llava:7b</a> 
<a href='./llava-llama3:8b.html'>llava-llama3:8b</a> 
<a href='./llava-phi3:3.8b.html'>llava-phi3:3.8b</a> 
<a href='./bakllava:7b.html'>bakllava:7b</a> 
<a href='./moondream:1.8b.html'>moondream:1.8b</a> 
</span>
</header>
<p>Prompt: (<a href='./prompt.txt'>raw</a>) (<a href='./act_as_an_ocr_assistant__analyze_the_provided_imag.prompt.yaml'>yaml</a>)
  words:57  bytes:376<br />
<textarea readonly rows='9'>Act as an OCR assistant. Analyze the provided image and:

1. Recognize all visible text in the image as accurately as possible.
2. Maintain the original structure and formatting of the text.
3. If any words or phrases are unclear, indicate this with [unclear] in your transcription.

Provide only the transcription without any additional comments.

Image: ./docs/run.page.png</textarea>
</p>
<div class='box'><a target='image' href='run.page.png'><img src='run.page.png' alt='./docs/run.page.png' width='250' /></a></div><br /><p>Output: qwen2.5vl:3b (<a href='./qwen2.5vl:3b.txt'>raw</a>)<br />
<textarea readonly rows='25'>ollama_multirun: my_hovercraft_is_full_of_eels

models: codellama:7b deepcoder:1.5b dolphin3:8b gemma:2b granite3:3.2b llama2-uncensored:7b mistral:7b qwen2.5-coder:7b qwen3:1.7b

Prompt: (raw) (yaml) words:6 bytes:30

My hovercraft is full of eels

| model | words | bytes | total duration | duration | load duration | prompt eval count | prompt eval duration | prompt eval rate | eval count | eval duration | eval rate |
|--------|-------|-------|----------------|----------|---------------|-------------------|----------------------|----------------|------------|--------------|----------|
| codellama:7b | 16 | 85 | 11.387706433s | 5.570671836s | 28 token(s) | 2.234853301s | 12.53 tokens/s | 25 token(s) | 3.580512222s | 6.98 tokens/s |
| deepcoder:1.5b | 89 | 541 | 7.290153172s | 1.718331149s | 11 token(s) | 154.603241ms | 71.15 tokens/s | 117 token(s) | 5.416341384s | 21.60 tokens/s |
| dolphin3:8b | 50 | 271 | 20.453919063s | 5.466473104s | 31 token(s) | 3.572317869s | 8.68 tokens/s | 62 token(s) | 11.413612053s | 5.43 tokens/s |
| gemma:2b | 24 | 138 | 5.021592452s | 2.355008541s | 29 token(s) | 554.850746ms | 52.27 tokens/s | 32 token(s) | 2.10987725s | 15.17 tokens/s |
| granite3:3.2b | 62 | 354 | 8.710353176s | 1.611366493s | 51 token(s) | 1.139311546s | 44.76 tokens/s | 91 token(s) | 5.957641006s | 15.27 tokens/s |
| llama2-uncensored:7b | 21 | 109 | 11.636989914s | 5.324974321s | 30 token(s) | 2.35815667s | 12.72 tokens/s | 27 token(s) | 3.952314728s | 6.83 tokens/s |
| mistral:7b | 88 | 516 | 25.830198391s | 3.925901498s | 13 token(s) | 1.652594407s | 7.87 tokens/s | 123 token(s) | 20.24976203s | 6.07 tokens/s |
| qwen2.5-coder:7b | 64 | 376 | 22.007981457s | 4.621085101s | 37 token(s) | 3.845300944s | 9.62 tokens/s | 75 token(s) | 13.539701277s | 5.54 tokens/s |
| qwen3:1.7b | 569 | 3447 | 47.333980943s | 2.204033628s | 16 token(s) | 240.671045ms | 66.48 tokens/s | 802 token(s) | 44.887396975s | 17.87 tokens/s |

Created: 2025-05-31 21:45:53

Generated with ollama_multirun v2.0</textarea>
</p>
<div class='box'><table>
<tr><td class='left' colspan='2'>Stats (<a href='./qwen2.5vl:3b.stats.txt'>raw</a>)</td></tr>
<tr><td class='left'>words</td><td>310</td></tr>
<tr><td class='left'>bytes</td><td>2020</td></tr>
<tr><td class='left'>total duration</td><td>1m49.637979292s</td></tr>
<tr><td class='left'>load duration</td><td>2.095332958s</td></tr>
<tr><td class='left'>prompt eval count</td><td>1349 token(s)</td></tr>
<tr><td class='left'>prompt eval duration</td><td>1m8.809896792s</td></tr>
<tr><td class='left'>prompt eval rate</td><td>19.60 tokens/s</td></tr>
<tr><td class='left'>eval count</td><td>1155 token(s)</td></tr>
<tr><td class='left'>eval duration</td><td>38.729022125s</td></tr>
<tr><td class='left'>eval rate</td><td>29.82 tokens/s</td></tr>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>Model (<a href='./qwen2.5vl:3b.info.txt'>raw</a>)</td></tr>
<tr><td class='left'>name</td><td class='left'><a target='ollama' href='https://ollama.com/library/qwen2.5vl:3b'>qwen2.5vl:3b</a></td></tr>
<tr><td class='left'>architecture</td><td class='left'>qwen25vl</td></tr>
<tr><td class='left'>size</td><td class='left'>6.2 GB</td></tr>
<tr><td class='left'>parameters</td><td class='left'>3.8B</td></tr>
<tr><td class='left'>context length</td><td class='left'>128000</td></tr>
<tr><td class='left'>embedding length</td><td  class='left'>2048</td></tr>
<tr><td class='left'>quantization</td><td class='left'>Q4_K_M</td></tr>
<tr><td class='left'>capabilities</td><td class='left'>completion<br />vision<br /></td>
</table></div>
<div class='box'><table>
<tr><td class='left' colspan='2'>System</td></tr>
<tr><td class='left'>ollama proc</td><td class='left'>100% GPU</td></tr>
<tr><td class='left'>ollama version</td><td class='left'>0.9.0</td></tr>
<tr><td class='left'>sys arch</td><td class='left'>arm64</td></tr>
<tr><td class='left'>sys processor</td><td class='left'>arm</td></tr>
<tr><td class='left'>sys memory</td><td class='left'>12G + 2029M</td></tr>
<tr><td class='left'>sys OS</td><td class='left'>Darwin 24.5.0</td></tr>
</table></div>
<br /><br />
<footer>
<p>page created:   2025-06-09 16:09:33</p>
<p>Generated with: <a target='ollama-multirun' href='https://github.com/attogram/ollama-multirun'>ollama-multirun</a> v4.2</p>
</footer></body></html>
